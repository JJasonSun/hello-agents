"""åè°ƒæ·±åº¦ç ”ç©¶å·¥ä½œæµçš„ç¼–æ’å™¨ã€‚"""

from __future__ import annotations

import logging
import re
from pathlib import Path
from queue import Empty, Queue
from threading import Lock, Thread
from typing import Any, Callable, Iterator

from hello_agents import HelloAgentsLLM, ToolAwareSimpleAgent
from hello_agents.tools import ToolRegistry
from hello_agents.tools.builtin.note_tool import NoteTool

from config import Configuration
from prompts import (
    report_writer_instructions,
    script_writer_instructions,
    task_summarizer_instructions,
    todo_planner_system_prompt,
)
from models import SummaryState, SummaryStateOutput, TodoItem
from services.planner import PlanningService
from services.reporter import ReportingService
from services.script_generator import ScriptGenerationService
from services.audio_generator import AudioGenerationService
from services.audio_synthesizer import PodcastSynthesisService
from services.search import dispatch_search, prepare_research_context
from services.summarizer import SummarizationService
from services.tool_events import ToolCallTracker

logger = logging.getLogger(__name__)


class DeepResearchAgent:
    """ä½¿ç”¨ HelloAgents åè°ƒåŸºäº TODO çš„ç ”ç©¶å·¥ä½œæµçš„åè°ƒå™¨ã€‚"""

    def __init__(self, config: Configuration | None = None) -> None:
        """ä½¿ç”¨é…ç½®å’Œå…±äº«å·¥å…·åˆå§‹åŒ–åè°ƒå™¨ã€‚"""
        self.config = config or Configuration.from_env()
        self.default_llm = self._init_llm(self.config.llm_model_id)
        self.smart_llm = self._init_llm(self.config.smart_llm_model)
        self.fast_llm = self._init_llm(self.config.fast_llm_model)

        self.note_tool = (
            NoteTool(workspace=self.config.notes_workspace)
            if self.config.enable_notes
            else None
        )
        self.tools_registry: ToolRegistry | None = None
        if self.note_tool:
            registry = ToolRegistry()
            registry.register_tool(self.note_tool)
            self.tools_registry = registry

        self._tool_tracker = ToolCallTracker(
            self.config.notes_workspace if self.config.enable_notes else None
        )
        self._tool_event_sink_enabled = False
        self._state_lock = Lock()

        self.todo_agent = self._create_tool_aware_agent(
            name="ç ”ç©¶è§„åˆ’ä¸“å®¶",
            system_prompt=todo_planner_system_prompt.strip(),
            llm=self.smart_llm,
        )
        self.report_agent = self._create_tool_aware_agent(
            name="æŠ¥å‘Šæ’°å†™ä¸“å®¶",
            system_prompt=report_writer_instructions.strip(),
            llm=self.smart_llm,
        )
        self.script_agent = self._create_tool_aware_agent(
            name="è„šæœ¬ç­–åˆ’ä¸“å®¶",
            system_prompt=script_writer_instructions.strip(),
            llm=self.default_llm,
        )

        self._summarizer_factory: Callable[[], ToolAwareSimpleAgent] = lambda: self._create_tool_aware_agent(  # noqa: E501
            name="ä»»åŠ¡æ€»ç»“ä¸“å®¶",
            system_prompt=task_summarizer_instructions.strip(),
            llm=self.fast_llm,
        )

        self.planner = PlanningService(self.todo_agent, self.config)
        self.summarizer = SummarizationService(self._summarizer_factory, self.config)
        self.reporting = ReportingService(self.report_agent, self.config)
        self.script_generator = ScriptGenerationService(self.script_agent, self.config)
        self.audio_generator = AudioGenerationService(self.config)

        self.podcast_synthesizer = PodcastSynthesisService(self.config)
        self._last_search_notices: list[str] = []

    # ------------------------------------------------------------------
    # å…¬å…± API
    # ------------------------------------------------------------------
    def _init_llm(self, model_id_override: str | None = None) -> HelloAgentsLLM:
        """æ ¹æ®é…ç½®åå¥½å®ä¾‹åŒ– HelloAgentsLLMã€‚"""
        llm_kwargs: dict[str, Any] = {"temperature": 0.0}

        model_id = model_id_override or self.config.llm_model_id
        if model_id:
            llm_kwargs["model"] = model_id

        provider = (self.config.llm_provider or "").strip()
        if provider:
            llm_kwargs["provider"] = provider

        if self.config.llm_base_url:
            llm_kwargs["base_url"] = self.config.llm_base_url
        if self.config.llm_api_key:
            llm_kwargs["api_key"] = self.config.llm_api_key

        return HelloAgentsLLM(**llm_kwargs)

    def _create_tool_aware_agent(self, *, name: str, system_prompt: str, llm: HelloAgentsLLM) -> ToolAwareSimpleAgent:
        """å®ä¾‹åŒ–å…±äº«å·¥å…·æ³¨å†Œè¡¨å’Œè·Ÿè¸ªå™¨çš„ ToolAwareSimpleAgentã€‚"""
        return ToolAwareSimpleAgent(
            name=name,
            llm=llm,
            system_prompt=system_prompt,
            enable_tool_calling=self.tools_registry is not None,
            tool_registry=self.tools_registry,
            tool_call_listener=self._tool_tracker.record,
        )

    def _set_tool_event_sink(self, sink: Callable[[dict[str, Any]], None] | None) -> None:
        """å¯ç”¨æˆ–ç¦ç”¨ç«‹å³å·¥å…·äº‹ä»¶å›è°ƒã€‚"""
        self._tool_event_sink_enabled = sink is not None
        self._tool_tracker.set_event_sink(sink)

    def run(self, topic: str) -> SummaryStateOutput:
        """
        æ‰§è¡Œç ”ç©¶å·¥ä½œæµå¹¶è¿”å›æœ€ç»ˆæŠ¥å‘Šï¼ˆåŒæ­¥æ¨¡å¼ï¼‰ã€‚
        
        æ­¤æ–¹æ³•æŒ‰é¡ºåºæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
        1. åˆå§‹åŒ–çŠ¶æ€å’Œè§„åˆ’ä»»åŠ¡ã€‚
        2. ä¸²è¡Œæ‰§è¡Œæ¯ä¸ªä»»åŠ¡ï¼ˆæœç´¢ + æ€»ç»“ï¼‰ã€‚
        3. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€‚
        4. ç”Ÿæˆæ’­å®¢è„šæœ¬ã€‚
        5. ç”ŸæˆéŸ³é¢‘æ–‡ä»¶å¹¶åˆæˆæ’­å®¢ã€‚
        """
        state = SummaryState(research_topic=topic)
        state.todo_items = self.planner.plan_todo_list(state)
        self._drain_tool_events(state)

        if not state.todo_items:
            logger.info("No TODO items generated; falling back to single task")
            state.todo_items = [self.planner.create_fallback_task(state)]

        for task in state.todo_items:
            for _ in self._execute_task(state, task, emit_stream=False):
                pass

        report = self.reporting.generate_report(state)
        self._drain_tool_events(state)
        state.structured_report = report
        state.running_summary = report
        self._persist_final_report(state, report)

        script = self.script_generator.generate_script(state)
        self._drain_tool_events(state)
        state.podcast_script = script

        # ä¸ºè„šæœ¬ç”ŸæˆéŸ³é¢‘
        task_id = f"task_{state.report_note_id}" if state.report_note_id else "task_default"
        audio_files = self.audio_generator.generate_audio(script, task_id)

        # åˆæˆæ’­å®¢
        podcast_file = self.podcast_synthesizer.synthesize_podcast(audio_files, task_id)
        
        return SummaryStateOutput(
            running_summary=report,
            report_markdown=report,
            todo_items=state.todo_items,
            podcast_script=script,
        )

    def run_stream(self, topic: str) -> Iterator[dict[str, Any]]:
        """
        æ‰§è¡Œç ”ç©¶å·¥ä½œæµå¹¶äº§ç”Ÿå¢é‡è¿›åº¦äº‹ä»¶ï¼ˆæµå¼æ¨¡å¼ï¼‰ã€‚
        
        æ­¤æ–¹æ³•ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œç ”ç©¶ä»»åŠ¡ï¼Œå¹¶é€šè¿‡ç”Ÿæˆå™¨å®æ—¶è¿”å›è¿›åº¦ã€‚
        ä¸»è¦æ­¥éª¤ï¼š
        1. åˆå§‹åŒ–å¹¶è§„åˆ’ä»»åŠ¡ã€‚
        2. ä¸ºæ¯ä¸ªä»»åŠ¡å¯åŠ¨ä¸€ä¸ªå·¥ä½œçº¿ç¨‹è¿›è¡Œå¹¶è¡Œå¤„ç†ã€‚
        3. å®æ—¶æµå¼ä¼ è¾“ä»»åŠ¡çŠ¶æ€ã€æœç´¢ç»“æœå’Œéƒ¨åˆ†æ€»ç»“ã€‚
        4. æ‰€æœ‰ä»»åŠ¡å®Œæˆåï¼Œç”Ÿæˆå¹¶æµå¼ä¼ è¾“æœ€ç»ˆæŠ¥å‘Šã€‚
        5. ç”Ÿæˆå¹¶æµå¼ä¼ è¾“æ’­å®¢è„šæœ¬å’ŒéŸ³é¢‘åˆæˆè¿›åº¦ã€‚
        """
        state = SummaryState(research_topic=topic)
        logger.debug("Starting streaming research: topic=%s", topic)
        yield {"type": "status", "message": "åˆå§‹åŒ–ç ”ç©¶æµç¨‹"}

        state.todo_items = self.planner.plan_todo_list(state)
        for event in self._drain_tool_events(state, step=0):
            yield event
        if not state.todo_items:
            state.todo_items = [self.planner.create_fallback_task(state)]

        channel_map: dict[int, dict[str, Any]] = {}
        for index, task in enumerate(state.todo_items, start=1):
            token = f"task_{task.id}"
            task.stream_token = token
            channel_map[task.id] = {"step": index, "token": token}

        # ç¡®ä¿åœ¨å¼€å§‹å¤šçº¿ç¨‹ä»»åŠ¡å‰ï¼Œæ˜¾å¼å‘é€ todo_list äº‹ä»¶
        # ä½¿ç”¨ list comprehension ç¡®ä¿ task è¢«æ­£ç¡®åºåˆ—åŒ–
        serialized_tasks = [self._serialize_task(t) for t in state.todo_items]
        logger.info(f"Emitting todo_list event with {len(serialized_tasks)} tasks")
        yield {
            "type": "todo_list",
            "tasks": serialized_tasks,
            "step": 0,
        }

        event_queue: Queue[dict[str, Any]] = Queue()

        def enqueue(
            event: dict[str, Any],
            *,
            task: TodoItem | None = None,
            step_override: int | None = None,
        ) -> None:
            payload = dict(event)
            target_task_id = payload.get("task_id")
            if task is not None:
                target_task_id = task.id
                payload["task_id"] = task.id

            channel = channel_map.get(target_task_id) if target_task_id is not None else None
            if channel:
                payload.setdefault("step", channel["step"])
                payload["stream_token"] = channel["token"]
            if step_override is not None:
                payload["step"] = step_override
            event_queue.put(payload)

        def tool_event_sink(event: dict[str, Any]) -> None:
            enqueue(event)

        self._set_tool_event_sink(tool_event_sink)

        threads: list[Thread] = []

        def worker(task: TodoItem, step: int) -> None:
            try:
                enqueue(
                    {
                        "type": "task_status",
                        "task_id": task.id,
                        "status": "in_progress",
                        "title": task.title,
                        "intent": task.intent,
                        "query": task.query,
                        "note_id": task.note_id,
                        "note_path": task.note_path,
                    },
                    task=task,
                )

                for event in self._execute_task(state, task, emit_stream=True, step=step):
                    enqueue(event, task=task)
            except Exception as exc:  # pragma: no cover - defensive guardrail
                logger.exception("Task execution failed", exc_info=exc)
                enqueue(
                    {
                        "type": "task_status",
                        "task_id": task.id,
                        "status": "failed",
                        "detail": str(exc),
                        "title": task.title,
                        "intent": task.intent,
                        "query": task.query,
                        "note_id": task.note_id,
                        "note_path": task.note_path,
                    },
                    task=task,
                )
            finally:
                enqueue({"type": "__task_done__", "task_id": task.id})

        for task in state.todo_items:
            step = channel_map.get(task.id, {}).get("step", 0)
            thread = Thread(target=worker, args=(task, step), daemon=True)
            threads.append(thread)
            thread.start()

        active_workers = len(state.todo_items)
        finished_workers = 0

        try:
            while finished_workers < active_workers:
                event = event_queue.get()
                if event.get("type") == "__task_done__":
                    finished_workers += 1
                    continue
                yield event

            while True:
                try:
                    event = event_queue.get_nowait()
                except Empty:
                    break
                if event.get("type") != "__task_done__":
                    yield event
        finally:
            self._set_tool_event_sink(None)
            for thread in threads:
                thread.join()

        yield {
            "type": "stage_change",
            "stage": "report",
            "message": "æ‰€æœ‰ç ”ç©¶ä»»åŠ¡å·²å®Œæˆï¼Œæ­£åœ¨æ’°å†™æ·±åº¦ç ”ç©¶æŠ¥å‘Š...",
        }
        yield {"type": "log", "message": f"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.config.smart_llm_model} æ¨¡å‹æ’°å†™æ·±åº¦æŠ¥å‘Š..."}
        report = self.reporting.generate_report(state)
        final_step = len(state.todo_items) + 1
        for event in self._drain_tool_events(state, step=final_step):
            yield event
        state.structured_report = report
        state.running_summary = report
        yield {"type": "log", "message": f"âœ“ æŠ¥å‘Šæ’°å†™å®Œæˆï¼Œå…± {len(report)} å­—ç¬¦"}

        note_event = self._persist_final_report(state, report)
        if note_event:
            yield note_event

        yield {
            "type": "final_report",
            "report": report,
            "note_id": state.report_note_id,
            "note_path": state.report_note_path,
        }

        yield {
            "type": "stage_change",
            "stage": "script",
            "message": "æ­£åœ¨å°†ç ”ç©¶æŠ¥å‘Šè½¬åŒ–ä¸ºåŒäººå¯¹è°ˆæ’­å®¢è„šæœ¬...",
        }
        yield {"type": "log", "message": f"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.config.fast_llm_model} æ¨¡å‹ç”Ÿæˆæ’­å®¢è„šæœ¬..."}
        yield {"type": "log", "message": "è„šæœ¬ç­–åˆ’ä¸“å®¶æ­£åœ¨åˆ›ä½œ Host (Xiayu) ä¸ Guest (Liwa) çš„å¯¹è¯..."}
        script = self.script_generator.generate_script(state)
        for event in self._drain_tool_events(state):
            yield event
        state.podcast_script = script
        
        script_turns = len(script) if script else 0
        yield {"type": "log", "message": f"âœ“ è„šæœ¬ç”Ÿæˆå®Œæˆï¼Œå…± {script_turns} è½®å¯¹è¯"}
        
        if script_turns == 0:
            yield {"type": "log", "message": "âš ï¸ è­¦å‘Šï¼šè„šæœ¬ä¸ºç©ºï¼Œå¯èƒ½æ˜¯è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥åç«¯æ—¥å¿—"}
        
        yield {
            "type": "podcast_script",
            "script": script,
            "turns": script_turns,
        }

        yield {
            "type": "stage_change",
            "stage": "audio",
            "message": "æ­£åœ¨è°ƒç”¨ TTS è¯­éŸ³å¼•æ“ç”ŸæˆéŸ³é¢‘...",
        }
        task_id = f"task_{state.report_note_id}" if state.report_note_id else "task_default"
        
        # ä½¿ç”¨é˜Ÿåˆ—å®ç°å®æ—¶æµå¼éŸ³é¢‘è¿›åº¦
        audio_event_queue: Queue[dict[str, Any]] = Queue()
        audio_result: list = []
        audio_error: list = []
        
        def audio_progress_callback(current, total, role, preview):
            """å°†è¿›åº¦äº‹ä»¶æ”¾å…¥é˜Ÿåˆ—ä»¥å®ç°å®æ—¶æ›´æ–°"""
            audio_event_queue.put({
                "type": "audio_progress",
                "current": current,
                "total": total,
                "role": role,
                "preview": preview,
                "message": f"[TTS {current}/{total}] æ­£åœ¨ä¸º {role} ç”Ÿæˆè¯­éŸ³: {preview}",
            })
        
        def run_audio_generation():
            """åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡ŒéŸ³é¢‘ç”Ÿæˆ"""
            try:
                files = self.audio_generator.generate_audio(script, task_id, audio_progress_callback)
                audio_result.append(files)
            except Exception as e:
                audio_error.append(str(e))
            finally:
                audio_event_queue.put({"type": "_audio_done"})
        
        yield {"type": "log", "message": f"å‡†å¤‡ä¸º {script_turns} æ®µå¯¹è¯ç”Ÿæˆè¯­éŸ³..."}
        
        yield {
            "type": "audio_start",
            "total": script_turns,
            "message": f"å¼€å§‹ç”Ÿæˆ {script_turns} æ®µè¯­éŸ³",
        }
        
        # åœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­å¯åŠ¨éŸ³é¢‘ç”Ÿæˆ
        audio_thread = Thread(target=run_audio_generation, daemon=True)
        audio_thread.start()
        
        # å®æ—¶æµå¼ä¼ è¾“è¿›åº¦äº‹ä»¶
        while True:
            try:
                event = audio_event_queue.get(timeout=0.1)
                if event.get("type") == "_audio_done":
                    break
                yield event
                # æ¯ä¸ªç‰‡æ®µå®Œæˆåå‘é€æˆåŠŸæ—¥å¿—
                if event.get("type") == "audio_progress":
                    yield {
                        "type": "log", 
                        "message": f"[TTS {event['current']}/{event['total']}] âœ“ {event['role']} è¯­éŸ³ç”ŸæˆæˆåŠŸ"
                    }
            except Empty:
                continue
        
        audio_thread.join(timeout=5.0)
        
        audio_files = audio_result[0] if audio_result else []
        audio_count = len(audio_files) if audio_files else 0
        
        if audio_error:
            yield {"type": "log", "message": f"âš ï¸ éŸ³é¢‘ç”Ÿæˆå‡ºé”™: {audio_error[0]}"}
        
        yield {"type": "log", "message": f"è¯­éŸ³ç”Ÿæˆå®Œæˆï¼ŒæˆåŠŸ {audio_count}/{script_turns} æ®µ"}
        
        yield {
            "type": "audio_generated",
            "files": audio_files,
            "count": audio_count,
        }

        yield {
            "type": "stage_change",
            "stage": "synthesis",
            "message": "æ­£åœ¨åˆæˆå®Œæ•´æ’­å®¢éŸ³é¢‘æ–‡ä»¶...",
        }
        yield {"type": "log", "message": "ä½¿ç”¨ FFmpeg æ‹¼æ¥æ‰€æœ‰è¯­éŸ³ç‰‡æ®µ..."}
        podcast_file = self.podcast_synthesizer.synthesize_podcast(audio_files, task_id)
        if podcast_file:
            yield {
                "type": "podcast_ready",
                "file": podcast_file,
            }

        yield {"type": "done"}

    # ------------------------------------------------------------------
    # æ‰§è¡ŒåŠ©æ‰‹
    # ------------------------------------------------------------------
    def _execute_task(
        self,
        state: SummaryState,
        task: TodoItem,
        *,
        emit_stream: bool,
        step: int | None = None,
    ) -> Iterator[dict[str, Any]]:
        """
        å¯¹å•ä¸ªä»»åŠ¡è¿è¡Œæœç´¢ + æ€»ç»“é€»è¾‘ã€‚
        
        Args:
            state: å…¨å±€ç ”ç©¶çŠ¶æ€ã€‚
            task: å½“å‰è¦æ‰§è¡Œçš„ä»»åŠ¡é¡¹ã€‚
            emit_stream: æ˜¯å¦äº§ç”Ÿæµå¼äº‹ä»¶ï¼ˆTrue ç”¨äº run_streamï¼ŒFalse ç”¨äº runï¼‰ã€‚
            step: å½“å‰æ­¥éª¤ç¼–å·ï¼ˆä»…ç”¨äºæµå¼äº‹ä»¶ï¼‰ã€‚
            
        Returns:
            äº‹ä»¶å­—å…¸çš„è¿­ä»£å™¨ï¼ˆå³ä½¿ emit_stream=Falseï¼Œä¹Ÿå¯èƒ½äº§ç”Ÿå°‘é‡å†…éƒ¨äº‹ä»¶ï¼Œé€šå¸¸è¢«å¿½ç•¥ï¼‰ã€‚
        """
        task.status = "in_progress"

        search_result, notices, answer_text, backend = dispatch_search(
            task.query,
            self.config,
            state.research_loop_count,
        )
        self._last_search_notices = notices
        task.notices = notices

        if emit_stream:
            for event in self._drain_tool_events(state, step=step):
                yield event
        else:
            self._drain_tool_events(state)

        if notices and emit_stream:
            for notice in notices:
                if notice:
                    yield {
                        "type": "status",
                        "message": notice,
                        "task_id": task.id,
                        "step": step,
                    }

        if not search_result or not search_result.get("results"):
            task.status = "skipped"
            if emit_stream:
                for event in self._drain_tool_events(state, step=step):
                    yield event
                yield {
                    "type": "task_status",
                    "task_id": task.id,
                    "status": "skipped",
                    "title": task.title,
                    "intent": task.intent,
                    "note_id": task.note_id,
                    "note_path": task.note_path,
                    "step": step,
                }
            else:
                self._drain_tool_events(state)
            return
        else:
            if not emit_stream:
                self._drain_tool_events(state)

        sources_summary, context = prepare_research_context(
            search_result,
            answer_text,
            self.config,
        )

        task.sources_summary = sources_summary

        with self._state_lock:
            state.web_research_results.append(context)
            state.sources_gathered.append(sources_summary)
            state.research_loop_count += 1

        summary_text: str | None = None

        if emit_stream:
            for event in self._drain_tool_events(state, step=step):
                yield event
            yield {
                "type": "sources",
                "task_id": task.id,
                "latest_sources": sources_summary,
                "raw_context": context,
                "step": step,
                "backend": backend,
                "note_id": task.note_id,
                "note_path": task.note_path,
            }

            summary_stream, summary_getter = self.summarizer.stream_task_summary(state, task, context)
            try:
                for event in self._drain_tool_events(state, step=step):
                    yield event
                for chunk in summary_stream:
                    if chunk:
                        yield {
                            "type": "task_summary_chunk",
                            "task_id": task.id,
                            "content": chunk,
                            "note_id": task.note_id,
                            "step": step,
                        }
                    for event in self._drain_tool_events(state, step=step):
                        yield event
            finally:
                summary_text = summary_getter()
        else:
            summary_text = self.summarizer.summarize_task(state, task, context)
            self._drain_tool_events(state)

        task.summary = summary_text.strip() if summary_text else "æš‚æ— å¯ç”¨ä¿¡æ¯"
        task.status = "completed"

        if emit_stream:
            for event in self._drain_tool_events(state, step=step):
                yield event
            yield {
                "type": "task_status",
                "task_id": task.id,
                "status": "completed",
                "title": task.title,
                "intent": task.intent,
                "summary": task.summary,
                "sources_summary": task.sources_summary,
                "note_id": task.note_id,
                "note_path": task.note_path,
                "step": step,
            }
        else:
            self._drain_tool_events(state)

    def _drain_tool_events(
        self,
        state: SummaryState,
        *,
        step: int | None = None,
    ) -> list[dict[str, Any]]:
        """å…±äº«å·¥å…·è°ƒç”¨è·Ÿè¸ªå™¨çš„ä»£ç†ã€‚"""
        events = self._tool_tracker.drain(state, step=step)
        if self._tool_event_sink_enabled:
            return []
        return events

    @property
    def _tool_call_events(self) -> list[dict[str, Any]]:
        """ä¸ºæ—§ç‰ˆé›†æˆæš´éœ²è®°å½•çš„å·¥å…·äº‹ä»¶ã€‚"""
        return self._tool_tracker.as_dicts()

    def _serialize_task(self, task: TodoItem) -> dict[str, Any]:
        """å°†ä»»åŠ¡æ•°æ®ç±»è½¬æ¢ä¸ºå‰ç«¯å¯åºåˆ—åŒ–çš„å­—å…¸ã€‚"""
        return {
            "id": task.id,
            "title": task.title,
            "intent": task.intent,
            "query": task.query,
            "status": task.status,
            "summary": task.summary,
            "sources_summary": task.sources_summary,
            "note_id": task.note_id,
            "note_path": task.note_path,
            "stream_token": task.stream_token,
        }

    def _persist_final_report(self, state: SummaryState, report: str) -> dict[str, Any] | None:
        if not self.note_tool or not report or not report.strip():
            return None

        note_title = f"ç ”ç©¶æŠ¥å‘Šï¼š{state.research_topic}".strip() or "ç ”ç©¶æŠ¥å‘Š"
        tags = ["deep_research", "report"]
        content = report.strip()

        note_id = self._find_existing_report_note_id(state)
        response = ""

        if note_id:
            response = self.note_tool.run(
                {
                    "action": "update",
                    "note_id": note_id,
                    "title": note_title,
                    "note_type": "conclusion",
                    "tags": tags,
                    "content": content,
                }
            )
            if response.startswith("âŒ"):
                note_id = None

        if not note_id:
            response = self.note_tool.run(
                {
                    "action": "create",
                    "title": note_title,
                    "note_type": "conclusion",
                    "tags": tags,
                    "content": content,
                }
            )
            note_id = self._extract_note_id_from_text(response)

        if not note_id:
            return None

        state.report_note_id = note_id
        if self.config.notes_workspace:
            note_path = Path(self.config.notes_workspace) / f"{note_id}.md"
            state.report_note_path = str(note_path)
        else:
            note_path = None

        payload = {
            "type": "report_note",
            "note_id": note_id,
            "title": note_title,
            "content": content,
        }
        if note_path:
            payload["note_path"] = str(note_path)

        return payload

    def _find_existing_report_note_id(self, state: SummaryState) -> str | None:
        """
        æŸ¥æ‰¾ä¸ç ”ç©¶ä¸»é¢˜ç›¸å…³çš„ç°æœ‰æŠ¥å‘Šç¬”è®° IDã€‚
        
        æ­¤æ–¹æ³•æ£€æŸ¥å½“å‰çŠ¶æ€æ˜¯å¦å·²å…³è”æŠ¥å‘Šç¬”è®° IDã€‚å¦‚æœæ²¡æœ‰ï¼Œå®ƒä¼šéå†å·²è®°å½•çš„å·¥å…·äº‹ä»¶ï¼Œ
        æŸ¥æ‰¾æœ€è¿‘åˆ›å»ºæˆ–æ›´æ–°çš„ç»“è®ºç±»å‹ç¬”è®°ï¼Œæ ‡é¢˜ä¸­åŒ…å«ç ”ç©¶ä¸»é¢˜çš„æŠ¥å‘Šã€‚
        
        Args:
            state: å½“å‰ç ”ç©¶çŠ¶æ€ï¼ŒåŒ…å«ç ”ç©¶ä¸»é¢˜å’Œå·²è®°å½•çš„å·¥å…·äº‹ä»¶ã€‚
            
        Returns:
            ä¸ç ”ç©¶ä¸»é¢˜ç›¸å…³çš„ç°æœ‰æŠ¥å‘Šç¬”è®° IDï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™ä¸º Noneã€‚
        """
        if state.report_note_id:
            return state.report_note_id

        for event in reversed(self._tool_tracker.as_dicts()):
            if event.get("tool") != "note":
                continue

            parameters = event.get("parsed_parameters") or {}
            if not isinstance(parameters, dict):
                continue

            action = parameters.get("action")
            if action not in {"create", "update"}:
                continue

            note_type = parameters.get("note_type")
            if note_type != "conclusion":
                title = parameters.get("title")
                if not (isinstance(title, str) and title.startswith("ç ”ç©¶æŠ¥å‘Š")):
                    continue

            note_id = parameters.get("note_id")
            if not note_id:
                note_id = self._tool_tracker._extract_note_id(event.get("result", ""))  # type: ignore[attr-defined]

            if note_id:
                return note_id

        return None

    @staticmethod
    def _extract_note_id_from_text(response: str) -> str | None:
        if not response:
            return None

        match = re.search(r"ID:\s*([^\n]+)", response)
        if not match:
            return None

        return match.group(1).strip()


def run_deep_research(topic: str, config: Configuration | None = None) -> SummaryStateOutput:
    """é•œåƒåŸºäºç±»çš„ API çš„ä¾¿æ·å‡½æ•°ã€‚"""
    agent = DeepResearchAgent(config=config)
    return agent.run(topic)
